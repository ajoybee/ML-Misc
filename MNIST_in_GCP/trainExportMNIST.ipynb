{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "example-2-simple-mnist.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "A0CtrE_Tt3Tk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Deploy MNIST in Google Cloud Platform\n",
        "\n",
        "1. Enhance handwritten digit recognition using tensorflow \n",
        "2. Save the model\n",
        "4. Use the model for prediction of couple of sample images. \n",
        "3. Export the model using tensorflow serving\n",
        "3. deploy it on the Google Cloud\n",
        "\n",
        "---\n",
        "\n",
        "## README\n",
        "```\n",
        "############################\n",
        "# Start a new VM in GCP\n",
        "############################\n",
        "1. Testing was done with CentOS 7\n",
        "\n",
        "############################\n",
        "# Install pip and tensorflow\n",
        "############################\n",
        "% sudo yum install python-pip \n",
        "% sudo pip install --upgrade pip\n",
        "% sudo yum -y install epel-release\n",
        "% sudo yum -y install gcc gcc-c++ python-pip python-devel atlas atlas-devel gcc-gfortran openssl-devel libffi-devel\n",
        "% sudo pip install --upgrade numpy scipy wheel cryptography \n",
        "% sudo pip install --upgrade tensorflow\n",
        "\n",
        "############################\n",
        "# Train and Export Model \n",
        "############################\n",
        "# Download files in Google Cloud Platform\n",
        "# Usage: mnist_saved_model.py [--training_epochs=x] [--model_version=y] export_dir\n",
        "% python trainExportMNIST.py --training_epochs=6 --model_version=1 exported_mnist_model\n",
        "\n",
        "# Test model for sanity\n",
        "saved_model_cli show --dir exported_mnist_model/1/ --all\n",
        "\n",
        "# Test model on two images\n",
        "saved_model_cli run --dir exported_mnist_model/1 --tag_set serve --signature_def predict_images --inputs images=two_images.npy \n",
        "\n",
        "############################\n",
        "# Transfer model to bucket\n",
        "############################\n",
        "% gsutil cp -r exported_mnist_model gs://exported_mnist_model\n",
        "```\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "prhe3ZxOaNBA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Usage: mnist_saved_model.py [--training_epochs=x] [--model_version=y] export_dir\n",
        "# example-2-simple-mnist.py\n",
        "import tensorflow as tf\n",
        "from datetime import datetime\n",
        "import time\n",
        "import os\n",
        "import sys\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "# Parse command line inputs\n",
        "tf.app.flags.DEFINE_integer('training_epochs', 6,\n",
        "                            'number of training iterations.')\n",
        "tf.app.flags.DEFINE_integer('model_version', 1, 'version number of the model.')\n",
        "tf.app.flags.DEFINE_string('work_dir', '/tmp', 'Working directory.')\n",
        "FLAGS = tf.app.flags.FLAGS\n",
        "\n",
        "\n",
        "# reset everything to rerun in jupyter\n",
        "tf.reset_default_graph()\n",
        "\n",
        "def main(_):\n",
        "        # Check inputs\n",
        "        if len(sys.argv) < 2 or sys.argv[-1].startswith('-'):\n",
        "          print('Usage: mnist_export.py [--training_epochs=x] '\n",
        "                '[--model_version=y] export_dir')\n",
        "          sys.exit(-1)\n",
        "        if FLAGS.training_epochs <= 0:\n",
        "          print('Please specify a positive value for training epochs. ')\n",
        "          sys.exit(-1)\n",
        "        if FLAGS.model_version <= 0:\n",
        "          print('Please specify a positive value for version number.')\n",
        "          sys.exit(-1)\n",
        "\n",
        "        # config\n",
        "        batch_size = 100\n",
        "        learning_rate = 0.5\n",
        "        layer1_size = 200\n",
        "        logs_path = 'tmp/mnistLogs' + datetime.now().strftime('%Y-%m-%d_%H-%M-%S'); #datetime.now().isoformat()\n",
        "\n",
        "        # load mnist data set\n",
        "        mnist = input_data.read_data_sets('tmp/MNIST_data', one_hot=True)\n",
        "\n",
        "        # input images\n",
        "\n",
        "        with tf.name_scope(\"weights\"):\n",
        "          W1 = tf.Variable(tf.truncated_normal([784, layer1_size], stddev=0.1))\n",
        "          W  = tf.Variable(tf.truncated_normal([layer1_size, 10], stddev=1.0))\n",
        "\n",
        "        with tf.name_scope('input'):\n",
        "          # None -> batch size can be any size, 784 -> flattened mnist image\n",
        "          #x = tf.placeholder(tf.float32, shape=[None, 784], name=\"x-input\")\n",
        "          serialized_tf_example = tf.placeholder(tf.string, name='tf_example')\n",
        "          feature_configs       = {'x': tf.FixedLenFeature(shape=[784], dtype=tf.float32),}\n",
        "          tf_example            = tf.parse_example(serialized_tf_example, feature_configs)\n",
        "          x                     = tf.identity(tf_example['x'], name='x-input')  # use tf.identity() to assign name\n",
        "\n",
        "          # target 10 output classes\n",
        "          y_ = tf.placeholder(tf.float32, shape=[None, 10], name=\"y-input\")\n",
        "\n",
        "        with tf.name_scope(\"biases\"):\n",
        "          b1 = tf.Variable(tf.zeros([layer1_size]))\n",
        "          b  = tf.Variable(tf.zeros([10]))\n",
        "\n",
        "        with tf.name_scope('hidden_layers'):\n",
        "          y1 = tf.nn.relu(tf.matmul(x, W1) + b1)\n",
        "\n",
        "        # implement model\n",
        "        with tf.name_scope(\"softmax\"):\n",
        "          ylogits = tf.matmul(y1, W) + b\n",
        "          y       = tf.nn.softmax(ylogits)\n",
        "          \n",
        "          # Classes for model export\n",
        "          values, indices    = tf.nn.top_k(y, 10)\n",
        "          table              = tf.contrib.lookup.index_to_string_table_from_tensor(\n",
        "                                                tf.constant([str(i) for i in range(10)]))\n",
        "          prediction_classes = table.lookup(tf.to_int64(indices))\n",
        "\n",
        "\n",
        "        # specify cost function\n",
        "        with tf.name_scope('cross_entropy'):\n",
        "          cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=ylogits, labels=y_)\n",
        "          cross_entropy = tf.reduce_mean(cross_entropy)\n",
        "\n",
        "        with tf.name_scope('train'):\n",
        "          train_op = tf.train.AdamOptimizer().minimize(cross_entropy)\n",
        "\n",
        "        with tf.name_scope('accuracy'):\n",
        "          # Accuracy\n",
        "          correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
        "          accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "        # create a summary for our cost and accuracy\n",
        "        train_cost_summary = tf.summary.scalar(\"train_cost\", cross_entropy)\n",
        "        train_acc_summary = tf.summary.scalar(\"train_accuracy\", accuracy)\n",
        "        test_cost_summary = tf.summary.scalar(\"test_cost\", cross_entropy)\n",
        "        test_acc_summary = tf.summary.scalar(\"test_accuracy\", accuracy)\n",
        "\n",
        "        # merge all summaries into a single \"operation\" which we can execute in a session\n",
        "        # summary_op = tf.summary.merge_all()\n",
        "\n",
        "        sess = tf.Session()\n",
        "        # variables need to be initialized before we can use them\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "\n",
        "        # create log writer object\n",
        "        writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
        "\n",
        "        # perform training cycles\n",
        "        for epoch in range(FLAGS.training_epochs):\n",
        "          \n",
        "          # number of batches in one epoch\n",
        "          batch_count = int(mnist.train.num_examples/batch_size)\n",
        "\n",
        "          for i in range(batch_count):\n",
        "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
        "\n",
        "            # perform the operations we defined earlier on batch\n",
        "            _, train_cost, train_acc, \\\n",
        "            _train_cost_summary, \\\n",
        "            _train_acc_summary = sess.run([train_op, cross_entropy, accuracy, \n",
        "                                           train_cost_summary,train_acc_summary], \n",
        "                                           feed_dict={x: batch_x, y_: batch_y})\n",
        "            # write log\n",
        "            writer.add_summary(_train_cost_summary, epoch * batch_count + i)\n",
        "            writer.add_summary(_train_acc_summary, epoch * batch_count + i)\n",
        "            if i % 100 == 0:\n",
        "                # for log on test data:\n",
        "                test_cost, test_acc, \\\n",
        "                _test_cost_summary, _test_acc_summary = sess.run([cross_entropy, accuracy,\n",
        "                                                                 test_cost_summary, test_acc_summary],\n",
        "                                                                 feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n",
        "                # write log\n",
        "                writer.add_summary(_test_cost_summary, epoch * batch_count + i)\n",
        "                writer.add_summary(_test_acc_summary, epoch * batch_count + i)\n",
        "                print('Epoch {0:3d}, Batch {1:3d} | Train Cost: {2:.2f} | Test Cost: {3:.2f} | Accuracy batch train: {4:.2f} | Accuracy test: {5:.2f}'\n",
        "                    .format(epoch, i, train_cost, test_cost, train_acc, test_acc))\n",
        "        print('Accuracy: {}'.format(accuracy.eval(session=sess, feed_dict={x: mnist.test.images, y_: mnist.test.labels})))\n",
        "        print('done')\n",
        "\n",
        "        # Export model\n",
        "        export_path_base = sys.argv[-1]\n",
        "        export_path = os.path.join(\n",
        "            tf.compat.as_bytes(export_path_base),\n",
        "            tf.compat.as_bytes(str(FLAGS.model_version)))\n",
        "        print('Exporting trained model to', export_path)\n",
        "        builder = tf.saved_model.builder.SavedModelBuilder(export_path)\n",
        "\n",
        "        # Build the signature_def_map.\n",
        "        classification_inputs = tf.saved_model.utils.build_tensor_info(serialized_tf_example)\n",
        "        classification_outputs_classes = tf.saved_model.utils.build_tensor_info(prediction_classes)\n",
        "        classification_outputs_scores = tf.saved_model.utils.build_tensor_info(values)\n",
        "\n",
        "        classification_signature = (\n",
        "            tf.saved_model.signature_def_utils.build_signature_def(\n",
        "                inputs={\n",
        "                    tf.saved_model.signature_constants.CLASSIFY_INPUTS : classification_inputs\n",
        "                },\n",
        "                outputs={\n",
        "                    tf.saved_model.signature_constants.CLASSIFY_OUTPUT_CLASSES: classification_outputs_classes,\n",
        "                    tf.saved_model.signature_constants.CLASSIFY_OUTPUT_SCORES : classification_outputs_scores\n",
        "                },\n",
        "                method_name=tf.saved_model.signature_constants.CLASSIFY_METHOD_NAME)\n",
        "        )\n",
        "        tensor_info_x = tf.saved_model.utils.build_tensor_info(x)\n",
        "        tensor_info_y = tf.saved_model.utils.build_tensor_info(y)\n",
        "\n",
        "        prediction_signature = (\n",
        "            tf.saved_model.signature_def_utils.build_signature_def(\n",
        "            inputs={'images': tensor_info_x},\n",
        "            outputs={'scores': tensor_info_y},\n",
        "            method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME))\n",
        "\n",
        "        legacy_init_op = tf.group(tf.tables_initializer(), name='legacy_init_op')\n",
        "\n",
        "        builder.add_meta_graph_and_variables(sess, \n",
        "                                             [tf.saved_model.tag_constants.SERVING], \n",
        "                                             signature_def_map={\n",
        "                                                 'predict_images': prediction_signature,\n",
        "                                                 tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY: classification_signature,\n",
        "                                             },\n",
        "                                             legacy_init_op=legacy_init_op)\n",
        "        builder.save()\n",
        "\n",
        "        print('Done exporting!')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  tf.app.run()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}